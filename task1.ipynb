{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEWEhvwAexZH",
        "outputId": "81897c07-9c19-479c-c853-bc227bebb4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries:\n",
        "import numpy as np                          # For numerical operations.\n",
        "from sklearn.datasets import load_iris       # To load the Iris dataset.\n",
        "from sklearn.linear_model import LogisticRegression  # Our classifier.\n",
        "from sklearn.model_selection import train_test_split  # For splitting data into training and test sets.\n",
        "from sklearn.metrics import classification_report     # For evaluating our model.\n",
        "\n",
        "# Load the Iris dataset.\n",
        "iris = load_iris()  # The Iris dataset is a classic dataset with 150 samples of iris flowers.\n",
        "X = iris.data       # Feature matrix: measurements like sepal length, sepal width, petal length, petal width.\n",
        "y = iris.target     # Target vector: numerical labels representing the iris species.\n",
        "\n",
        "# Split the data into training and testing subsets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "# test_size=0.3 -- 30% of data is reserved for testing.\n",
        "# random_state=42 ensures reproducibility of the split.\n",
        "\n",
        "# Initialize the Logistic Regression classifier.\n",
        "clf = LogisticRegression(max_iter=200)\n",
        "# max_iter=200 sets the maximum number of iterations (to ensure convergence for this dataset).\n",
        "\n",
        "# Train the classifier on the training data.\n",
        "clf.fit(X_train, y_train)  # The model learns the mapping from features to iris species.\n",
        "\n",
        "# Use the trained model to predict the test set labels.\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print the classification report to evaluate performance.\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "JCtrJNmtwb65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries:\n",
        "import nltk                                # For natural language processing tasks.\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download the VADER lexicon, needed by the SentimentIntensityAnalyzer.\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Initialize the sentiment analyzer.\n",
        "sid = SentimentIntensityAnalyzer()         # VADER is optimized for social media text and other short texts.\n",
        "\n",
        "# Define a sample text.\n",
        "text = \"I absolutely loved the new design of the application. It is magnificent!\"\n",
        "\n",
        "# Compute sentiment scores.\n",
        "scores = sid.polarity_scores(text)\n",
        "# polarity_scores returns a dictionary with sentiment keys: 'neg', 'neu', 'pos', and 'compound'.\n",
        "\n",
        "# Print the sentiment scores.\n",
        "print(\"Sentiment Scores:\", scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BOknb0FfP2r",
        "outputId": "51eb6c2a-3827-4aec-b4af-48421d44341f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Scores: {'neg': 0.0, 'neu': 0.518, 'pos': 0.482, 'compound': 0.855}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "# Build the neural network model\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGsD18ZcrQ76",
        "outputId": "8b3f5732-eceb-40c9-ddec-b03383f3032a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8600 - loss: 0.4815\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.1530\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9661 - loss: 0.1119\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9743 - loss: 0.0847\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9770 - loss: 0.0728\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9723 - loss: 0.0950\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08225271850824356, 0.9754999876022339]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries:\n",
        "import cv2          # OpenCV library for computer vision.\n",
        "import matplotlib.pyplot as plt  # For plotting images using matplotlib.\n",
        "\n",
        "# Load a sample image from disk.\n",
        "# Replace 'sample.jpg' with the path to an actual image file.\n",
        "image = cv2.imread('sample.jpg')\n",
        "# imread loads the image in BGR (Blue, Green, Red) format.\n",
        "\n",
        "# Check if the image was correctly loaded.\n",
        "if image is None:\n",
        "    print(\"Error: Unable to load image file.\")\n",
        "else:\n",
        "    # Convert image to grayscale.\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # cvtColor converts the image from BGR to Grayscale.\n",
        "\n",
        "    # Apply Canny edge detection.\n",
        "    edges = cv2.Canny(gray_image, threshold1=100, threshold2=200)\n",
        "    # Canny detects edges by finding areas of strong intensity gradients.\n",
        "\n",
        "    # Display the original and edge-detected images side by side.\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct color display.\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(edges, cmap='gray')\n",
        "    plt.title('Edge Detection')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsc2EruFvCmm",
        "outputId": "ff1727e9-2756-4850-c4d5-b09726099975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Unable to load image file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i56PKBrEzAGb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}